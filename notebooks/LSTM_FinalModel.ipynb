{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gci_CRkHnHCS",
    "outputId": "2ffaaba6-54b1-41e6-bf73-1a02e96c67e3"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in ./.local/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: nltk in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: gensim in ./.local/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: sklearn in ./.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.8/site-packages (3.5.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: astunparse==1.6.3 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in ./.local/lib/python3.8/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in ./.local/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in ./.local/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: joblib in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./.local/lib/python3.8/site-packages (from gensim) (4.0.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from gensim) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in ./.local/lib/python3.8/site-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in ./.local/lib/python3.8/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: packaging in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: sacremoses in ./.local/lib/python3.8/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: filelock in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /data/rc/apps/rc/software/Anaconda3/2020.07/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in ./.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow nltk gensim sklearn transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gl8rF1E4nFu1",
    "outputId": "86197ac7-a76e-4004-e1e4-b91b875abfe4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/chrico/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/chrico/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Lambda, Embedding, GRU, Bidirectional, Concatenate, Dense\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import gensim.downloader\n",
    "import re\n",
    "from calendar import day_name, day_abbr, month_name, month_abbr\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfQyxJASnFu4",
    "outputId": "66a73e47-d43c-4b14-ce83-9958199ae23d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 1.64 s, total: 43.2 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# download our pretrained word embedding with embedding size of 300\n",
    "EMBED_SIZE = 300\n",
    "gn300 = gensim.downloader.load('word2vec-google-news-300')\n",
    "\n",
    "# \"\"\"\n",
    "# Condense our pretrained word embedding using the following two techniques:\n",
    "# 1) remove stopwords\n",
    "# 2) make all keys lowercase, group by key, and take average per key.\n",
    "# E.g. (gn300['beyonce'] +\n",
    "#       gn300['Beyonce'] +\n",
    "#       gn300['BEYONCE']) / 3 -> gn300['beyonce']\n",
    "# \"\"\"\n",
    "# S = Counter() # vector sum\n",
    "# C = Counter() # vector count\n",
    "# for word in gn300.vocab:\n",
    "#     lower = word.lower()\n",
    "#     if lower in stopwords: continue\n",
    "#     S[lower] += gn300[word]\n",
    "#     C[lower] += 1\n",
    "# # create condensed word2vec (just a simple dictionary)\n",
    "# gn300 = {w: s / c for w, s, c in zip(S.keys(), S.values(), C.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ahmP6lSPnFu3"
   },
   "outputs": [],
   "source": [
    "# constants that will be used as tokens\n",
    "PAD = '~PAD~'\n",
    "URL = '~URL~'\n",
    "DATETIME = '~DATETIME~'\n",
    "QUANTITY = '~QUANTITY~'\n",
    "NUM = '~NUM~'\n",
    "UNK = '~UNK~'\n",
    "\n",
    "# regexes to be applied prior to tokenization\n",
    "url_regex = '(www\\.|http://|https://)\\S+|\\S+\\.(co|org|net|info|be|gov|edu|html|jpg|jpeg|png|gif)'\n",
    "date_regex = '('        + '|'.join(day_name[i] for i in range(7)) +\\\n",
    "             '|'        + '|'.join(day_abbr[i] for i in range(7)) +\\\n",
    "             ')?,?\\s?(' + '|'.join(month_name[i] for i in range(1, 13)) +\\\n",
    "             '|'        + '|'.join(month_abbr[i] for i in range(1, 13)) +\\\n",
    "             \")\\s\\d{1,2}(st|nd|rd|th)?(,?\\s'?\\d{2,4})?\"\n",
    "time_regex = '((\\d+\\:\\d+)(\\s?[AaPp]\\.\\s?[Mm]\\.)?)|((\\d+\\:\\d+\\s?)?([AaPp]\\.\\s?[Mm]\\.))'\n",
    "quantity_regex = '\\d+((\\,?\\d+)+)?'\n",
    "\n",
    "# list of stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-z4drYwanFu3"
   },
   "outputs": [],
   "source": [
    "### HYPERPARAMETERS ###\n",
    "PERCENT_TEST = 0.075\n",
    "PERCENT_VAL  = 0.075\n",
    "MAX_TEXT_LEN = 512\n",
    "MAX_TITLE_LEN = 40\n",
    "TEXT_UNITS = 64\n",
    "TITLE_UNITS = 5\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 2e-3\n",
    "DROPOUT = 0.2\n",
    "OPTIMIZER = tf.keras.optimizers.Nadam\n",
    "PLATEAU_FACTOR = 0.63\n",
    "\n",
    "val_split = PERCENT_VAL / (1 - PERCENT_TEST)\n",
    "optimizer = OPTIMIZER(learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint_v0'\n",
    "\n",
    "### RANDOM SEED (for reproducibility) ###\n",
    "SEED = 42\n",
    "np.random.seed (SEED)\n",
    "seed = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "90aB_d5BnFu6"
   },
   "outputs": [],
   "source": [
    "def strip_all_duplicates(df):\n",
    "    r = pd.DataFrame()\n",
    "    for column in ['title', 'text']:\n",
    "        c = df[column]\n",
    "        flag = c.isin(c[c.duplicated()])\n",
    "        r = pd.concat([r, df.loc[flag]])\n",
    "    r = r.drop_duplicates()\n",
    "    return df[~df.index.isin(r.index)], r\n",
    "\n",
    "def get_real_fake(df):\n",
    "    real = df[df.label.isin([0, 'REAL'])]\n",
    "    fake = df[df.label.isin([1, 'FAKE'])]\n",
    "    return real, fake\n",
    "\n",
    "def split_df(df):\n",
    "    global seed\n",
    "    train, test = train_test_split(df, test_size=PERCENT_TEST, random_state=seed)\n",
    "    seed += 1\n",
    "    train, val  = train_test_split(train, test_size=val_split, random_state=seed)\n",
    "    seed += 1\n",
    "    return train, val, test\n",
    "\n",
    "def concat_and_shuffle(dfs):\n",
    "    global seed\n",
    "    df = pd.concat(dfs)\n",
    "    df = df.sample(frac=1, random_state=seed)\n",
    "    seed += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "t-bINh9knFu6",
    "outputId": "e049424d-63e2-471a-a3f6-d12a9c2bd1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6306 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5923 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                          You Can Smell Hillary’s Fear   \n",
       "1     Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           Kerry to go to Paris in gesture of sympathy   \n",
       "3     Bernie supporters on Twitter erupt in anger ag...   \n",
       "4      The Battle of New York: Why This Primary Matters   \n",
       "...                                                 ...   \n",
       "6330  State Department says it can't find emails fro...   \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[5923 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "if not os.path.exists('news.csv'):\n",
    "    !unzip 'news.csv.zip'\n",
    "df = pd.read_csv('news.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.drop_duplicates()\n",
    "print (len(df), len(pd.read_csv('news.csv')) - len(df))\n",
    "df, _ = strip_all_duplicates(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8wWZQVq7nFu6"
   },
   "outputs": [],
   "source": [
    "real, fake = get_real_fake(df)\n",
    "\n",
    "real_train, real_val, real_test = split_df(real)\n",
    "fake_train, fake_val, fake_test = split_df(fake)\n",
    "\n",
    "# def split_by_author(df):\n",
    "#     # take counts grouped by author\n",
    "#     author = df.author.value_counts()\n",
    "#     # split authors into groups\n",
    "#     author_train, author_val, author_test = split_df(author)\n",
    "#     # split data by author group\n",
    "#     train = df[df.author.isin(author_train.index)].copy(deep=True)\n",
    "#     val   = df[df.author.isin(author_val.index)].copy(deep=True)\n",
    "#     test  = df[df.author.isin(author_test.index)].copy(deep=True)\n",
    "#     return train, val, test\n",
    "\n",
    "# real_train, real_val, real_test = split_by_author(real)\n",
    "# fake_train, fake_val, fake_test = split_by_author(fake)\n",
    "\n",
    "# real_author_counts = real.author.value_counts()\n",
    "# fake_author_counts = fake.author.value_counts()\n",
    "# mixed_authors = real_author_counts.index.intersection(fake_author_counts.index)\n",
    "# real_author_counts[mixed_authors], fake_author_counts[mixed_authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2TujNkAnFu6",
    "outputId": "3d4bdaff-321b-43a1-9385-1ed2d127c4d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516 2517\n",
      "222 223\n",
      "222 223\n"
     ]
    }
   ],
   "source": [
    "train = concat_and_shuffle([real_train, fake_train])\n",
    "val   = concat_and_shuffle([real_val, fake_val])\n",
    "test  = concat_and_shuffle([real_test, fake_test])\n",
    "\n",
    "# Expected result of val_split. This is just to give us a\n",
    "# sense of the distribution of labels.\n",
    "def display_count(df):\n",
    "    print (len(df[df.label.isin([0, 'REAL'])]),\n",
    "           len(df[df.label.isin([1, 'FAKE'])]))\n",
    "display_count (train)\n",
    "display_count (val)\n",
    "display_count (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8jMIyCWCnFu6"
   },
   "outputs": [],
   "source": [
    "# def supertokenize(text):\n",
    "#     # e.g. split_by_case('ILoveNewYork') == ['I', 'Love', 'New', 'York']\n",
    "#     def split_by_case(s):\n",
    "#         if (not s[1:].isupper()) and (not s[1:].islower()):\n",
    "#             for i in range(1, len(s) - 1):\n",
    "#                 if s[i].isupper():\n",
    "#                     return [s[:i]] + split_by_case(s[i:])\n",
    "#                 elif s[i + 1].isupper():\n",
    "#                     return [s[:i + 1]] + split_by_case(s[i + 1:])\n",
    "#         return [s]\n",
    "#     text = re.sub(quantity_regex, QUANTITY, \n",
    "#                  re.sub(time_regex, DATETIME, \n",
    "#                         re.sub(date_regex, DATETIME, \n",
    "#                                re.sub(url_regex, URL, text))))\n",
    "#     text = text.replace('•', '')\n",
    "#     raw_tokens = nltk.word_tokenize(text)\n",
    "#     tokens = []\n",
    "#     for t in raw_tokens:\n",
    "#         if t in '!\"\\'(),--./:;<?[\\\\]{|}“”‘’—': continue\n",
    "#         if t.lower() != \"n't\": t = re.sub('[\\\"\\']', '', t)\n",
    "#         if (len(t) > 2) and (t.lower() == t) and (t[-1] == '.'): t = t[:-1]\n",
    "#         if t == URL:\n",
    "#             tokens.append (URL)\n",
    "#             continue\n",
    "#         if (t == DATETIME) or (re.sub('^\\d+(/\\d+)+$', '', t) == ''):\n",
    "#             tokens.append (DATETIME)\n",
    "#             continue\n",
    "#         if t == QUANTITY:\n",
    "#             tokens.append (QUANTITY)\n",
    "#             continue\n",
    "#         if t.isnumeric() or (t[:-2].isnumeric() and (\n",
    "#             t[-2:] in ['st', 'nd', 'rd', 'th'])):\n",
    "#             tokens.append (NUM)\n",
    "#             continue\n",
    "#         t = t.lower()\n",
    "#         if t in stopwords: continue\n",
    "#         if t in gn300:\n",
    "#             tokens.append (t)\n",
    "#         else:\n",
    "#             if t + '.' in gn300:\n",
    "#                 tokens.append (t + '.')\n",
    "#                 continue\n",
    "#             if t.replace('.', '') in gn300:\n",
    "#                 tokens.append (t.replace('.', ''))\n",
    "#                 continue\n",
    "#             is_found = False\n",
    "#             for x in split_by_case(re.sub('[^a-z]', '', t)):\n",
    "#                 if x in gn300:\n",
    "#                     tokens.append (x)\n",
    "#                     is_found = True\n",
    "#             if is_found: continue\n",
    "#             for st in re.split('-', re.sub('[^a-z0-9\\.~]', '-', t)):\n",
    "#                 for x in [st, st[:-1], st[1:], st.replace('s', 'z'), \n",
    "#                           st.replace('ou', 'o'), st.replace('re', 'er')]:\n",
    "#                     if x in gn300:\n",
    "#                         tokens.append (x)\n",
    "#                         is_found = True\n",
    "#                         break\n",
    "#             if not is_found: tokens.append (UNK)\n",
    "#     return tokens\n",
    "# TOKENIZE_FN = supertokenize\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_tokenize = lambda txt: bert_tokenizer.decode(bert_tokenizer.encode(txt))\n",
    "# TOKENIZE_FN = bert_tokenize\n",
    "TOKENIZE_FN = nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jm1e4rHZnFu7"
   },
   "outputs": [],
   "source": [
    "# this does tokenization as well as tracking token counts grouped by label\n",
    "def tokenize_and_update_word_counts(text, label, tokenize_fn):\n",
    "    global tc_real, tc_fake\n",
    "    tokens = tokenize_fn(text)\n",
    "    tc = Counter(tokens)\n",
    "    if label in [0, 'REAL']:\n",
    "        tc_fake += tc\n",
    "    elif label in [1, 'FAKE']:\n",
    "        tc_real += tc\n",
    "    else:\n",
    "        warnings.warn('Unexpected label %s'.format(label))\n",
    "    return tokens\n",
    "\n",
    "def TERM_FREQ_FN(a, b):\n",
    "    return abs(a - b) / np.sqrt(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0eT6JSFnFu7",
    "outputId": "102db3e9-ff63-4765-8e42-a91e39035ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 257 ms, total: 43.4 s\n",
      "Wall time: 43.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34808,\n",
       " [(\"''\", 97.7829389051427),\n",
       "  ('``', 96.31319114069542),\n",
       "  (\"'s\", 95.57467706163249),\n",
       "  ('said', 85.235463653618),\n",
       "  ('.', 80.94643585404079),\n",
       "  (',', 79.21328629016182),\n",
       "  ('he', 72.61887101094638),\n",
       "  ('a', 68.43106620918628),\n",
       "  ('the', 62.89938200692574),\n",
       "  ('his', 60.56906441510858)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tc_real = Counter()\n",
    "tc_fake = Counter()\n",
    "\n",
    "train['tokenized_title'] = train.apply(\n",
    "    lambda x, y: tokenize_and_update_word_counts(\n",
    "        x.title, x.label, y), axis=1, args=(TOKENIZE_FN,))\n",
    "train['tokenized_text'] = train.apply(\n",
    "    lambda x, y: tokenize_and_update_word_counts(\n",
    "        x.text, x.label, y), axis=1, args=(TOKENIZE_FN,))\n",
    "\n",
    "T = Counter()\n",
    "for k in tc_real + tc_fake:\n",
    "    T[k] = TERM_FREQ_FN(tc_real[k], tc_fake[k])\n",
    "\n",
    "thresh = T.most_common(25000)[-1][1]\n",
    "tokens = [k for k, v in T.items() if v >= thresh]\n",
    "\n",
    "vocab, i = {PAD: 0, URL: 1, DATETIME: 2, QUANTITY: 3, NUM: 4, UNK: 5}, 6\n",
    "for w in tokens:\n",
    "    if w in (PAD, URL, DATETIME, QUANTITY, NUM, UNK): continue\n",
    "    vocab[w] = i\n",
    "    i += 1\n",
    "id2word = {v: k for k, v in vocab.items()}\n",
    "\n",
    "i, T.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjPY5yx3nFu8",
    "outputId": "97e93897-879c-48db-96ab-5d78518e86d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.58 s, sys: 37.8 ms, total: 5.62 s\n",
      "Wall time: 5.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val['tokenized_title']  = val.apply(lambda x: TOKENIZE_FN(x.title), axis=1)\n",
    "val['tokenized_text']   = val.apply(lambda x: TOKENIZE_FN(x.text), axis=1)\n",
    "test['tokenized_title'] = test.apply(lambda x: TOKENIZE_FN(x.title), axis=1)\n",
    "test['tokenized_text']  = test.apply(lambda x: TOKENIZE_FN(x.text), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dUdbbIp8nFu8"
   },
   "outputs": [],
   "source": [
    "def clean(text,length):\n",
    "    f = [vocab[w] if w in vocab else vocab[UNK] for w in text]\n",
    "    f = f[:length]\n",
    "    return (length - len(f)) * [vocab[PAD]] + f\n",
    "train['text_as_ints']  = train.tokenized_text.apply(clean, args=[MAX_TEXT_LEN])\n",
    "train['title_as_ints'] = train.tokenized_text.apply(clean, args=[MAX_TITLE_LEN])\n",
    "val['text_as_ints']    = val.tokenized_text.apply(clean, args=[MAX_TEXT_LEN])\n",
    "val['title_as_ints']   = val.tokenized_text.apply(clean, args=[MAX_TITLE_LEN])\n",
    "test['text_as_ints']   = test.tokenized_text.apply(clean, args=[MAX_TEXT_LEN])\n",
    "test['title_as_ints']  = test.tokenized_text.apply(clean, args=[MAX_TITLE_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gZCNdIn-nFu8"
   },
   "outputs": [],
   "source": [
    "X_train = [np.array(train.text_as_ints.to_list()),\n",
    "           np.array(train.title_as_ints.to_list())]\n",
    "X_val   = [np.array(val.text_as_ints.to_list()),\n",
    "           np.array(val.title_as_ints.to_list())]\n",
    "X_test  = [np.array(test.text_as_ints.to_list()),\n",
    "           np.array(test.title_as_ints.to_list())]\n",
    "\n",
    "# binarize labels\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train = lb.fit_transform(train.label)\n",
    "y_val = lb.fit_transform(val.label)\n",
    "y_test = lb.fit_transform(test.label)\n",
    "\n",
    "# compute class weights based on training labels\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced', classes=[0, 1], y=[w for x in y_train for w in x])\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of9_Mx9rnFu8",
    "outputId": "aabf9700-df54-4833-ea05-001ba6bc7dd4"
   },
   "outputs": [],
   "source": [
    "def generate_embedding():\n",
    "    emb = np.zeros((len(vocab), EMBED_SIZE))\n",
    "    v = np.random.uniform(-1, 1, EMBED_SIZE)\n",
    "    for i in range(len(vocab)):\n",
    "        try:\n",
    "            g = gn300[id2word[i]]\n",
    "            emb[i] = g + v * np.linalg.norm(g) / np.linalg.norm(v)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return Embedding(input_dim=emb.shape[0],\n",
    "                     output_dim=emb.shape[1],\n",
    "                     weights=[emb],\n",
    "                     trainable=False)\n",
    "gru = lambda units: GRU(units, dropout=DROPOUT, recurrent_dropout=DROPOUT)\n",
    "mask = Lambda(lambda inputs: K.not_equal(inputs, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of9_Mx9rnFu8",
    "outputId": "aabf9700-df54-4833-ea05-001ba6bc7dd4"
   },
   "outputs": [],
   "source": [
    "input_text = Input(shape=[None])\n",
    "emb_text = generate_embedding()(input_text)\n",
    "gru_text = Bidirectional(gru(TEXT_UNITS))(emb_text, mask=mask(input_text))\n",
    "\n",
    "input_title = Input(shape=[None])\n",
    "emb_title = generate_embedding()(input_title)\n",
    "gru_title = gru(TITLE_UNITS)(emb_title, mask=mask(input_title))\n",
    "\n",
    "concat = Concatenate()([gru_text, gru_title])\n",
    "output = Dense(1, activation='sigmoid')(concat)\n",
    "model = tf.keras.Model(inputs=[input_text, input_title], outputs=output)\n",
    "\n",
    "def run_model():\n",
    "    model.summary ()\n",
    "    model.compile (loss='binary_crossentropy',\n",
    "                   optimizer=optimizer,\n",
    "                   metrics='accuracy')\n",
    "    model.fit (X_train, y_train,\n",
    "               batch_size=BATCH_SIZE,\n",
    "               class_weight=class_weights,\n",
    "               validation_data=(X_val, y_val),\n",
    "               epochs=EPOCHS,\n",
    "               callbacks=[\n",
    "                   tf.keras.callbacks.ModelCheckpoint(\n",
    "                       filepath=checkpoint_filepath,\n",
    "                       monitor='val_accuracy',\n",
    "                       save_weights_only=True,\n",
    "                       save_best_only=True),\n",
    "                   tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                       factor=PLATEAU_FACTOR,\n",
    "                       patience=2,\n",
    "                       cooldown=1,\n",
    "                       verbose=1)]\n",
    "    )\n",
    "    model.load_weights (checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of9_Mx9rnFu8",
    "outputId": "aabf9700-df54-4833-ea05-001ba6bc7dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    10442400    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    10442400    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          140544      embedding[0][0]                  \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 5)            4605        embedding_1[0][0]                \n",
      "                                                                 lambda[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 133)          0           bidirectional[0][0]              \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            134         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,030,083\n",
      "Trainable params: 145,283\n",
      "Non-trainable params: 20,884,800\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 80s 506ms/step - loss: 0.4028 - accuracy: 0.8246 - val_loss: 0.3181 - val_accuracy: 0.8607\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 79s 500ms/step - loss: 0.2770 - accuracy: 0.8883 - val_loss: 0.2605 - val_accuracy: 0.9079\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 78s 495ms/step - loss: 0.2232 - accuracy: 0.9078 - val_loss: 0.9002 - val_accuracy: 0.6157\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - 79s 498ms/step - loss: 0.1871 - accuracy: 0.9279 - val_loss: 0.2466 - val_accuracy: 0.8989\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 78s 493ms/step - loss: 0.1520 - accuracy: 0.9406 - val_loss: 0.1992 - val_accuracy: 0.9281\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - 79s 497ms/step - loss: 0.1244 - accuracy: 0.9507 - val_loss: 0.2007 - val_accuracy: 0.9236\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 79s 498ms/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.1575 - val_accuracy: 0.9461\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - 77s 486ms/step - loss: 0.0883 - accuracy: 0.9660 - val_loss: 0.1792 - val_accuracy: 0.9326\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.9752\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0012600000598467886.\n",
      "158/158 [==============================] - 79s 502ms/step - loss: 0.0702 - accuracy: 0.9752 - val_loss: 0.1647 - val_accuracy: 0.9483\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - 79s 500ms/step - loss: 0.0475 - accuracy: 0.9843 - val_loss: 0.2180 - val_accuracy: 0.9348\n"
     ]
    }
   ],
   "source": [
    "run_model ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Of9_Mx9rnFu8",
    "outputId": "aabf9700-df54-4833-ea05-001ba6bc7dd4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0imzn2gZnFu8",
    "outputId": "ef8d4c00-10dc-4e8d-938d-ca4424fe56cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    10442400    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None)         0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    10442400    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128)          140544      embedding[0][0]                  \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 5)            4605        embedding_1[0][0]                \n",
      "                                                                 lambda[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 133)          0           bidirectional[0][0]              \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            134         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 21,030,083\n",
      "Trainable params: 21,030,083\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "158/158 [==============================] - 93s 589ms/step - loss: 0.0958 - accuracy: 0.9644 - val_loss: 0.1028 - val_accuracy: 0.9640\n",
      "Epoch 2/10\n",
      "158/158 [==============================] - 89s 565ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0959 - val_accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "158/158 [==============================] - 90s 571ms/step - loss: 7.2182e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9730\n",
      "Epoch 4/10\n",
      "158/158 [==============================] - ETA: 0s - loss: 4.0496e-04 - accuracy: 1.0000\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0012600000598467886.\n",
      "158/158 [==============================] - 89s 563ms/step - loss: 4.0496e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "158/158 [==============================] - 88s 558ms/step - loss: 2.4659e-04 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9730\n",
      "Epoch 6/10\n",
      "158/158 [==============================] - ETA: 0s - loss: 2.0021e-04 - accuracy: 1.0000\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0007938000303693116.\n",
      "158/158 [==============================] - 88s 560ms/step - loss: 2.0021e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "158/158 [==============================] - 88s 556ms/step - loss: 1.7807e-04 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9730\n",
      "Epoch 8/10\n",
      "158/158 [==============================] - ETA: 0s - loss: 1.7310e-04 - accuracy: 1.0000\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000940308673307.\n",
      "158/158 [==============================] - 87s 550ms/step - loss: 1.7310e-04 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "158/158 [==============================] - 88s 559ms/step - loss: 1.5868e-04 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "158/158 [==============================] - ETA: 0s - loss: 1.4571e-04 - accuracy: 1.0000\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00031505923834629357.\n",
      "158/158 [==============================] - 87s 552ms/step - loss: 1.4571e-04 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "run_model ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_IzFKCtnFu8",
    "outputId": "0c540303-58d4-44e2-9adb-671cd36bdc80",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 65ms/step - loss: 0.0996 - accuracy: 0.9708\n",
      "0.941582838443825\n",
      "[[216   7]\n",
      " [  6 216]]\n",
      "[1] [0.00148377]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('DR. MANNY: Water crisis in Flint is just the tip of the iceberg',\n",
       " \"The water crisis in Flint, Mich., is just the tip of the iceberg – and if you think that it can’t happen in your community, you’re sadly mistaken. The aging water infrastructure in this country is deeply flawed. Many of the 150,000 public water systems that serve more than 300 million people are based on rusting, leaky pipes and decades-old plans that— if not corrected and replaced— will have devastating and long-lasting effects on our communities.\\n\\nThe disaster in Flint, which began in 2014 when the city switched its water supply from Detroit’s system to the Flint River in a cost-saving measure, is likely brewing in many other communities. It is inconceivable to me that in the most developed nation on the planet, we have exposed families and young children to the poisonous effects of lead. And it is almost criminal to me that water supply officials were unaware that the water pumping through a large American city was endangering the community. That level of negligence is beyond comprehension.\\n\\nThe dangerous, detrimental effects that lead can have on a developing brain and body are well-documented. In 1978, a largely successful campaign to remove lead from home paint products resulted in a new law, after it was found that small children could mistakenly eat paint chips and be exposed to lead poisoning. When it comes to levels of lead in water, no true amount is safe. However, in 1991 the Environmental Protection Agency (EPA) established an action level for lead in public drinking water at 15 micrograms per liter, and required water supplies to routinely test household tap water to check lead levels.\\n\\nThese laws and others were established to protect our citizens from both indirect and direct exposure to the harmful compound. A person can be directly exposed to lead by drinking contaminated water with unsafe levels, while indirect exposure can occur when a person inhales contaminated water particles through steam or vapors.\\n\\nOnce lead enters the human body, the heavy metal attaches itself to cells that can begin to build up in bones or major organs like the liver or kidneys. It disrupts the normal cellular biology of the organ and can lead to chronic diseases. However, the most dangerous damage lead poisoning can inflict is on the brain, especially in young or unborn children. If lead is deposited in a developing fetal brain, it can disrupt the normal function and cause irreversible damage. The same can happen in young children whose brains are still maturing.\\n\\nThe consequences can result in low IQ, severe delays in cognitive function, significant disruption in the memory center of the brain, learning disabilities and other neurological deficits. The devastating part of this diagnosis is that it is, for the most part, irreversible. Patients exposed to acute lead poisoning can be treated through chelation, which is a method used to filter out the lead. However, for children chronically exposed over a period of time, the damage cannot be undone.\\n\\nThis makes the preventable crisis in Flint all the more devastating.\\n\\nI read that the Obama administration is planning to pick Dr. Nicole Lurie to act as a “czar” and fix the crisis in Flint, but I urge her to look further than just Michigan. Lurie and others must start to seriously evaluate other areas of America where the people are most susceptible to a disaster such as this. The government failed the city of Flint, it must act now to protect the rest of us.\\n\\n\\n\\nDr. Manny Alvarez serves as Fox News Channel's senior managing health editor. He also serves as chairman of the department of obstetrics/gynecology and reproductive science at Hackensack University Medical Center in New Jersey. Click here for more information on Dr. Manny's work with Hackensack University Medical Center. Visit AskDrManny.com for more.\\n\\n\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate (X_test, y_test)\n",
    "\n",
    "logits = model.predict(X_test)\n",
    "y_pred = np.round(logits)\n",
    "\n",
    "print (matthews_corrcoef(y_test, y_pred))\n",
    "print (confusion_matrix(y_test, y_pred))\n",
    "\n",
    "most_off = np.argmax(np.abs(y_test - logits))\n",
    "print (y_test[most_off], logits[most_off])\n",
    "test.iloc[most_off].title, test.iloc[most_off].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "4uoimiYInFu8"
   },
   "outputs": [],
   "source": [
    "def get_reshaped_weights(model,layer_id):\n",
    "    W = np.array(model.layers[layer_id].get_weights())\n",
    "    W = W.reshape(W.shape[1], W.shape[2])\n",
    "    return W\n",
    "text_embed = get_reshaped_weights(model,2)\n",
    "title_embed = get_reshaped_weights(model,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hnpwuIgBnFu8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-f883d067f1c4>:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cs = W.dot(b) / (np.linalg.norm(W, axis=1) * np.linalg.norm(b))\n",
      "<ipython-input-24-f883d067f1c4>:4: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  n_ = np.sum(arr >= thresh)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_top_n_plus_ties(arr, n):\n",
    "    sorted_args = np.argsort(-arr)\n",
    "    thresh = arr[sorted_args[n]]\n",
    "    n_ = np.sum(arr >= thresh)\n",
    "    return sorted_args[:n_]\n",
    "def get_most_similar(word, W, n):\n",
    "    b = W[vocab[word]]\n",
    "    cs = W.dot(b) / (np.linalg.norm(W, axis=1) * np.linalg.norm(b))\n",
    "    return get_top_n_plus_ties(cs, n)\n",
    "def create_words_plot(embed1, embed2, WORD, k=9):\n",
    "    ids1 = get_most_similar(WORD, embed1, k - 1)\n",
    "    ids2 = get_most_similar(WORD, embed2, k - 1)\n",
    "    words1 = [id2word[i] for i in ids1]\n",
    "    words2 = [id2word[i] for i in ids2]\n",
    "    v = TSNE(n_components=2, random_state=SEED).fit_transform(\n",
    "        np.concatenate([embed1[ids1], embed2[ids2]]))\n",
    "    plt.figure (figsize=(15,15))\n",
    "    plt.scatter (v[:k,0], v[:k, 1], facecolors='none', edgecolors='teal')\n",
    "    plt.scatter (v[k:,0], v[k:, 1], facecolors='none', edgecolors='red')\n",
    "    for i, word in enumerate(words1):\n",
    "        plt.annotate (word, (v[i, 0], v[i, 1]), size=9.5)\n",
    "        if word == WORD:\n",
    "            plt.scatter (v[i, 0], v[i, 1], c='teal', s=300)\n",
    "    for i, word in enumerate(words2):\n",
    "        plt.annotate (word, (v[i + k, 0], v[i + k, 1]), size=9.5)\n",
    "        if word == WORD:\n",
    "            plt.scatter (v[i + k, 0], v[i + k, 1], c='red', s=300)\n",
    "create_words_plot (text_embed, title_embed, 'headline')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_BaseModel",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
